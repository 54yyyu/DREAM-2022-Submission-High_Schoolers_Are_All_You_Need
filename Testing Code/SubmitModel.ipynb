{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01539fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tfomics.layers import RevCompConv1D\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pk\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0831a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevCompConv1D(tf.keras.layers.Conv1D):\n",
    "    \"\"\"\n",
    "    Implement forward and reverse-complement filter convolutions\n",
    "    for 1D signals. It takes as input either a single input or two inputs \n",
    "    (where the second input is the reverse complement scan). If a single input, \n",
    "    this performs both forward and reverse complement scans and either merges it \n",
    "    (if concat=True) or returns a separate scan for forward and reverse comp. \n",
    "    \"\"\"\n",
    "    def __init__(self, *args, concat=True, **kwargs):\n",
    "        super(RevCompConv1D, self).__init__(*args, **kwargs)\n",
    "        self.concat = concat\n",
    "\n",
    "\n",
    "    def call(self, inputs, inputs2=None):\n",
    "\n",
    "        if inputs2 is not None:\n",
    "          # create rc_kernels\n",
    "            rc_kernel = self.kernel[::-1,::-1,:]\n",
    "\n",
    "            # convolution 1D\n",
    "            outputs = self.convolution_op(inputs, self.kernel)\n",
    "            rc_outputs = self.convolution_op(inputs2, rc_kernel)\n",
    "\n",
    "        else:\n",
    "          # create rc_kernels\n",
    "            rc_kernel = tf.concat([self.kernel, self.kernel[::-1,:,:][:,::-1,:]], axis=-1)\n",
    "\n",
    "            # convolution 1D\n",
    "            outputs = self._convolution_op(inputs, rc_kernel)\n",
    "\n",
    "            # unstack to forward and reverse strands\n",
    "            outputs = tf.unstack(outputs, axis=2)\n",
    "            rc_outputs = tf.stack(outputs[self.filters:], axis=2)\n",
    "            outputs = tf.stack(outputs[:self.filters], axis=2)\n",
    "\n",
    "        # add bias\n",
    "        if self.use_bias:\n",
    "            outputs = tf.nn.bias_add(outputs, self.bias)\n",
    "            rc_outputs = tf.nn.bias_add(rc_outputs, self.bias)\n",
    "\n",
    "        # add activations\n",
    "        if self.activation is not None:\n",
    "            outputs = self.activation(outputs)\n",
    "            rc_outputs = self.activation(rc_outputs)\n",
    "\n",
    "        if self.concat:\n",
    "            return tf.concat([outputs, rc_outputs], axis=-1)\n",
    "        else:\n",
    "            return outputs, rc_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa1baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfileModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, bin_size=1, rc_prob=0.5, *args, **kwargs):\n",
    "        super(ProfileModel, self).__init__(*args, **kwargs)\n",
    "        self.bin_size = bin_size\n",
    "        self.rc_prob = rc_prob\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ProfileModel, self).get_config()\n",
    "        config.update({\"bin_size\": self.bin_size})\n",
    "        config.update({'rc_prob': self.rc_prob})\n",
    "        return config\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if len(data) == 3:\n",
    "            x, y, sample_weight = data\n",
    "        else:\n",
    "            sample_weight = None\n",
    "            x, y = data\n",
    "\n",
    "        # online target resolution calculation\n",
    "        y = bin_resolution(y, self.bin_size)\n",
    "\n",
    "        # stochastic reverse complement\n",
    "        x, y = reverse_complement(x, y, p=self.rc_prob)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  \n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "    def test_step(self, data):\n",
    "        if len(data) == 3:\n",
    "            x, y, sample_weight = data\n",
    "        else:\n",
    "            sample_weight = None\n",
    "            x, y = data\n",
    "\n",
    "\n",
    "        # online target resolution calculation\n",
    "        y = bin_resolution(y, self.bin_size)\n",
    "\n",
    "        y_pred = self(x, training=False)\n",
    "        x_RC, y_RC = reverse_complement(x, y, p=1.0)\n",
    "        y_pred_RC = self(x_RC, training=False)\n",
    "        y_pred = tf.math.reduce_mean([y_pred, y_pred_RC], axis=0)\n",
    "        self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "\"\"\"    def compute_loss(self, x, y, y_pred, sample_weight):\n",
    "        del x  # The default implementation does not use `x`.\n",
    "        return self.compiled_loss(\n",
    "            y, y_pred, sample_weight, regularization_losses=self.losses)\"\"\"\n",
    "    \n",
    "\n",
    "def reverse_complement(x, y, p=0.5):\n",
    "    x_rc = tf.gather(x, [3, 2, 1, 0], axis=-1)\n",
    "    x_rc = tf.reverse(x_rc, axis=[1])\n",
    "    # y_rc = tf.reverse(y, axis=[1])\n",
    "    switch = tf.random.uniform(shape=[]) > (1 - p)\n",
    "    x_new = tf.cond(switch, lambda: x_rc, lambda: x)\n",
    "    # y_new = tf.cond(switch, lambda: y_rc, lambda: y)\n",
    "    return x_new, y\n",
    "\n",
    "def bin_resolution(y, bin_size):\n",
    "    if bin_size > 1:\n",
    "        y_dim = tf.shape(y)\n",
    "        num_bins = tf.cast(y_dim[1] / bin_size, 'int32')\n",
    "        y_reshape = tf.reshape(y, (y_dim[0], num_bins, bin_size, y_dim[2]))\n",
    "        y_bin = tf.math.reduce_mean(y_reshape, axis=2)\n",
    "        return y_bin\n",
    "    else:\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e705c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention2(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, *args, embedding_size=None, **kwargs):\n",
    "        super(MultiHeadAttention2, self).__init__(*args, **kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.embedding_size = d_model if embedding_size == None else embedding_size\n",
    "\n",
    "        assert d_model % self.num_heads == 0 and d_model % 6 == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "        self.wk = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "        self.wv = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "        \n",
    "        self.r_k_layer = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "        self.r_w = tf.Variable(tf.random_normal_initializer(0, 0.5)(shape=[1, self.num_heads, 1, self.depth]), trainable=True, name=f'{self.name}-r_w')\n",
    "        self.r_r = tf.Variable(tf.random_normal_initializer(0, 0.5)(shape=[1, self.num_heads, 1, self.depth]), trainable=True, name=f'{self.name}-r_r')\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"d_model\": self.d_model,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            'embedding_size': self.embedding_size\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def split_heads(self, x, batch_size, seq_len):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, seq_len, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        seq_len = tf.constant(q.shape[1])\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size, seq_len)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size, seq_len)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size, seq_len)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        q = q / tf.math.sqrt(tf.cast(self.depth, dtype=tf.float32))\n",
    "        \n",
    "        pos = tf.range(-seq_len + 1, seq_len, dtype=tf.float32)[tf.newaxis]\n",
    "        feature_size=self.embedding_size//6\n",
    "\n",
    "        seq_length = tf.cast(seq_len, dtype=tf.float32)\n",
    "        exp1 = f_exponential(tf.abs(pos), feature_size, seq_length=seq_length)\n",
    "        exp2 = tf.multiply(exp1, tf.sign(pos)[..., tf.newaxis])\n",
    "        cm1 = f_central_mask(tf.abs(pos), feature_size, seq_length=seq_length)\n",
    "        cm2 = tf.multiply(cm1, tf.sign(pos)[..., tf.newaxis])\n",
    "        gam1 = f_gamma(tf.abs(pos), feature_size, seq_length=seq_length)\n",
    "        gam2 = tf.multiply(gam1, tf.sign(pos)[..., tf.newaxis])\n",
    "\n",
    "        # [1, 2seq_len - 1, embedding_size]\n",
    "        positional_encodings = tf.concat([exp1, exp2, cm1, cm2, gam1, gam2], axis=-1)\n",
    "        positional_encodings = tf.keras.layers.Dropout(0.1)(positional_encodings)\n",
    "        \n",
    "        # [1, 2seq_len - 1, d_model]\n",
    "        r_k = self.r_k_layer(positional_encodings)\n",
    "        \n",
    "        # [1, 2seq_len - 1, num_heads, depth]\n",
    "        r_k = tf.reshape(r_k, [r_k.shape[0], r_k.shape[1], self.num_heads, self.depth])\n",
    "        r_k = tf.transpose(r_k, perm=[0, 2, 1, 3])\n",
    "        # [1, num_heads, 2seq_len - 1, depth]\n",
    "        \n",
    "        # [batch_size, num_heads, seq_len, seq_len]\n",
    "        content_logits = tf.matmul(q + self.r_w, k, transpose_b=True)\n",
    "        \n",
    "        # [batch_size, num_heads, seq_len, 2seq_len - 1]\n",
    "        relative_logits = tf.matmul(q + self.r_r, r_k, transpose_b=True)\n",
    "        # [batch_size, num_heads, seq_len, seq_len]\n",
    "        relative_logits = relative_shift(relative_logits)\n",
    "        \n",
    "        # [batch_size, num_heads, seq_len, seq_len]\n",
    "        logits = content_logits + relative_logits\n",
    "        attention_map = tf.nn.softmax(logits)\n",
    "        \n",
    "        # [batch_size, num_heads, seq_len, depth]\n",
    "        attended_values = tf.matmul(attention_map, v)\n",
    "        # [batch_size, seq_len, num_heads, depth]\n",
    "        attended_values = tf.transpose(attended_values, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(attended_values, [batch_size, seq_len, self.d_model])\n",
    "        \n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        return output, attention_map\n",
    "\n",
    "\n",
    "def f_exponential(positions, feature_size, seq_length=None, min_half_life=3.0):\n",
    "    if seq_length is None:\n",
    "        seq_length = tf.cast(tf.reduce_max(tf.abs(positions)) + 1, dtype=tf.float32)\n",
    "    max_range = tf.math.log(seq_length) / tf.math.log(2.0)\n",
    "    half_life = tf.pow(2.0, tf.linspace(min_half_life, max_range, feature_size))\n",
    "    half_life = tf.reshape(half_life, shape=[1]*positions.shape.rank + half_life.shape)\n",
    "    positions = tf.abs(positions)\n",
    "    outputs = tf.exp(-tf.math.log(2.0) / half_life * positions[..., tf.newaxis])\n",
    "    return outputs\n",
    "\n",
    "def f_central_mask(positions, feature_size, seq_length=None):\n",
    "    center_widths = tf.pow(2.0, tf.range(1, feature_size + 1, dtype=tf.float32)) - 1\n",
    "    center_widths = tf.reshape(center_widths, shape=[1]*positions.shape.rank + center_widths.shape)\n",
    "    outputs = tf.cast(center_widths > tf.abs(positions)[..., tf.newaxis], tf.float32)\n",
    "    return outputs\n",
    "\n",
    "def f_gamma(positions, feature_size, seq_length=None):\n",
    "    if seq_length is None:\n",
    "        seq_length = tf.reduce_max(tf.abs(positions)) + 1\n",
    "    stdv = seq_length / (2*feature_size)\n",
    "    start_mean = seq_length / feature_size\n",
    "    mean = tf.linspace(start_mean, seq_length, num=feature_size)\n",
    "    mean = tf.reshape(mean, shape=[1]*positions.shape.rank + mean.shape)\n",
    "    concentration = (mean / stdv) ** 2\n",
    "    rate = mean / stdv**2\n",
    "    def gamma_pdf(x, conc, rt):\n",
    "        log_unnormalized_prob = tf.math.xlogy(concentration - 1., x) - rate * x\n",
    "        log_normalization = (tf.math.lgamma(concentration) - concentration * tf.math.log(rate))\n",
    "        return tf.exp(log_unnormalized_prob - log_normalization)\n",
    "    probabilities = gamma_pdf(tf.abs(tf.cast(positions, dtype=tf.float32))[..., tf.newaxis], concentration, rate)\n",
    "    outputs = probabilities / tf.reduce_max(probabilities)\n",
    "    return outputs\n",
    "    \n",
    "def relative_shift(x):\n",
    "    to_pad = tf.zeros_like(x[..., :1])\n",
    "    x = tf.concat([to_pad, x], -1)\n",
    "    _, num_heads, t1, t2 = x.shape\n",
    "    x = tf.reshape(x, [-1, num_heads, t2, t1])\n",
    "    x = tf.slice(x, [0, 0, 1, 0], [-1, -1, -1, -1])\n",
    "    x = tf.reshape(x, [-1, num_heads, t1, t2 - 1])\n",
    "    x = tf.slice(x, [0, 0, 0, 0], [-1, -1, -1, (t2 + 1) // 2])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5429aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.util.tf_export import tf_export\n",
    "from tensorflow.python.util import dispatch\n",
    "\n",
    "def gelu(features, approximate=False, name=None):\n",
    "    with ops.name_scope(name, \"Gelu\", [features]):\n",
    "        features = ops.convert_to_tensor(features, name=\"features\")\n",
    "        if not features.dtype.is_floating:\n",
    "            raise ValueError(\n",
    "              \"`features.dtype` must be a floating point tensor.\"\n",
    "              f\"Received:features.dtype={features.dtype}\")\n",
    "        if approximate:\n",
    "            coeff = math_ops.cast(0.044715, features.dtype)\n",
    "            return 0.5 * features * (\n",
    "                1.0 + math_ops.tanh(0.7978845608028654 *\n",
    "                              (features + coeff * math_ops.pow(features, 3))))\n",
    "        else:\n",
    "            return 0.5 * features * (1.0 + math_ops.erf(\n",
    "                features / math_ops.cast(1.4142135623730951, features.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0fb8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(input_layer, kernel_size=3, activation='relu', num_layers=5, dropout=0.1):\n",
    "\n",
    "    filters = input_layer.shape.as_list()[-1]  \n",
    "\n",
    "    nn = tf.keras.layers.Conv1D(filters=filters,\n",
    "                           kernel_size=kernel_size,\n",
    "                           activation=None,\n",
    "                           use_bias=False,\n",
    "                           padding='same',\n",
    "                           dilation_rate=1)(input_layer) \n",
    "    nn = tf.keras.layers.BatchNormalization()(nn)\n",
    "\n",
    "    base_rate = 2\n",
    "    for i in range(1,num_layers):\n",
    "        nn = tf.keras.layers.Activation('relu')(nn)\n",
    "        nn = tf.keras.layers.Dropout(dropout)(nn)\n",
    "        nn = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                 kernel_size=kernel_size,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 dilation_rate=base_rate**i)(nn) \n",
    "        nn = tf.keras.layers.BatchNormalization()(nn)\n",
    "    nn = tf.keras.layers.add([input_layer, nn])\n",
    "    return tf.keras.layers.Activation(activation)(nn)\n",
    "\n",
    "\n",
    "def stoch_residual_block(input_layer, kernel_size=3, activation='relu', num_layers=5, dropout=0.1):\n",
    "\n",
    "    filters = input_layer.shape.as_list()[-1]  \n",
    "\n",
    "    nn = tf.keras.layers.Conv1D(filters=filters,\n",
    "                           kernel_size=kernel_size,\n",
    "                           activation=None,\n",
    "                           use_bias=False,\n",
    "                           padding='same',\n",
    "                           dilation_rate=1)(input_layer) \n",
    "    nn = tf.keras.layers.BatchNormalization()(nn)\n",
    "\n",
    "    base_rate = 2\n",
    "    for i in range(1,num_layers):\n",
    "        nn = tf.keras.layers.Activation('relu')(nn)\n",
    "        nn = tf.keras.layers.Dropout(dropout)(nn)\n",
    "        nn = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                 kernel_size=kernel_size,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 dilation_rate=base_rate**i)(nn) \n",
    "        nn = tf.keras.layers.BatchNormalization()(nn)\n",
    "    nn = tfa.layers.StochasticDepth(0.5)([input_layer, nn])\n",
    "    return tf.keras.layers.Activation(activation)(nn)\n",
    "\n",
    "def convnext_block(input_layer, kernel_size=3, activation='relu', num_layers=5, dropout=0.1):\n",
    "\n",
    "    filters = input_layer.shape.as_list()[-1]\n",
    "    nn = input_layer \n",
    "\n",
    "    base_rate = 2\n",
    "    for i in range(1,num_layers):\n",
    "        nn = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                 kernel_size=kernel_size,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 dilation_rate=base_rate**i)(nn) \n",
    "        nn = keras.layers.LayerNormalization()(nn)\n",
    "        nn = keras.layers.Conv1D(filters*4, kernel_size=1)(nn)\n",
    "        # nn = keras.layers.Activation('gelu')(nn)\n",
    "        nn = keras.layers.Activation(gelu)(nn)\n",
    "        nn = keras.layers.Conv1D(filters, kernel_size=1)(nn)\n",
    "        nn = keras.layers.Dropout(dropout)(nn)\n",
    "    nn = tf.keras.layers.Add()([input_layer, nn])\n",
    "    return nn\n",
    "\n",
    "\n",
    "def stoch_transformer_block(input_layer, num_heads=8, d_model=96, bottle_neck=8):\n",
    "\n",
    "    nn = input_layer\n",
    "    nn1, att = MultiHeadAttention2(num_heads=num_heads, d_model=d_model)(nn, nn, nn)\n",
    "    nn1 = keras.layers.Dropout(0.2)(nn1)\n",
    "    nn = tf.add(nn1, nn)\n",
    "    nn = keras.layers.LayerNormalization()(nn)\n",
    "    nn1 = keras.layers.Dense(bottle_neck)(nn)\n",
    "    nn1 = keras.layers.Dense(d_model)(nn1)\n",
    "    nn1 = keras.layers.Dropout(0.1)(nn1)\n",
    "    nn = tf.add(nn1, nn)\n",
    "    nn = keras.layers.LayerNormalization()(nn)\n",
    "\n",
    "    return tfa.layers.StochasticDepth(0.5)([input_layer, nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4accff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title EEE Paper Layers (rc_Conv1D + Feedforward + ScaledDotProductAttention + MultiHeadAttention)\n",
    "\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class rc_Conv1D(keras.layers.Conv1D):\n",
    "\n",
    "    def __init__(self, *args, concat=False, **kwargs):\n",
    "        super(rc_Conv1D, self).__init__(*args, **kwargs)\n",
    "        self.concat = concat\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        length = conv_utils.conv_output_length(input_shape[1],\n",
    "                                               self.kernel_size[0],\n",
    "                                               padding=self.padding,\n",
    "                                               stride=self.strides[0])\n",
    "        return [(input_shape[0], length, self.filters),\n",
    "                (input_shape[0], length, self.filters)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #create a rev-comped kernel.\n",
    "        #kernel shape is (width, input_channels, filters)\n",
    "        #Rev comp is along both the length (dim 0) and input channel (dim 1)\n",
    "        #axes; that is the reason for ::-1, ::-1 in the first and second dims.\n",
    "        #The rev-comp of channel at index i should be at index i\n",
    "        revcomp_kernel =\\\n",
    "            K.concatenate([self.kernel,\n",
    "                           self.kernel[::-1,::-1,:]],axis=-1)\n",
    "        if (self.use_bias):\n",
    "            revcomp_bias = K.concatenate([self.bias,\n",
    "                                          self.bias], axis=-1)\n",
    "\n",
    "        outputs = K.conv1d(inputs, revcomp_kernel,\n",
    "                           strides=self.strides[0],\n",
    "                           padding=self.padding,\n",
    "                           data_format=self.data_format,\n",
    "                           dilation_rate=self.dilation_rate[0])\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs += K.bias_add(outputs,\n",
    "                                  revcomp_bias,\n",
    "                                  data_format=self.data_format)\n",
    "\n",
    "        if (self.activation is not None):\n",
    "            outputs = self.activation(outputs)\n",
    "        x_f = outputs[:,:,:int(outputs.get_shape().as_list()[-1]/2)]\n",
    "        x_rc = outputs[:,:,int(outputs.get_shape().as_list()[-1]/2):]\n",
    "\n",
    "        if self.concat:\n",
    "              return tf.concat([x_f, os.XATTR_REPLACE], axis=-1)\n",
    "        else:\n",
    "              return [x_f, x_rc]\n",
    "\n",
    "\n",
    "class LayerNormalization2(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 epsilon=None,\n",
    "                 gamma_initializer='ones',\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_constraint=None,\n",
    "                 beta_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"Layer normalization layer\n",
    "        See: [Layer Normalization](https://arxiv.org/pdf/1607.06450.pdf)\n",
    "        :param center: Add an offset parameter if it is True.\n",
    "        :param scale: Add a scale parameter if it is True.\n",
    "        :param epsilon: Epsilon for calculating variance.\n",
    "        :param gamma_initializer: Initializer for the gamma weight.\n",
    "        :param beta_initializer: Initializer for the beta weight.\n",
    "        :param gamma_regularizer: Optional regularizer for the gamma weight.\n",
    "        :param beta_regularizer: Optional regularizer for the beta weight.\n",
    "        :param gamma_constraint: Optional constraint for the gamma weight.\n",
    "        :param beta_constraint: Optional constraint for the beta weight.\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "        super(LayerNormalization2, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon() * K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma_initializer = keras.initializers.get(gamma_initializer)\n",
    "        self.beta_initializer = keras.initializers.get(beta_initializer)\n",
    "        self.gamma_regularizer = keras.regularizers.get(gamma_regularizer)\n",
    "        self.beta_regularizer = keras.regularizers.get(beta_regularizer)\n",
    "        self.gamma_constraint = keras.constraints.get(gamma_constraint)\n",
    "        self.beta_constraint = keras.constraints.get(beta_constraint)\n",
    "        self.gamma, self.beta = None, None\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'epsilon': self.epsilon,\n",
    "            'gamma_initializer': keras.initializers.serialize(self.gamma_initializer),\n",
    "            'beta_initializer': keras.initializers.serialize(self.beta_initializer),\n",
    "            'gamma_regularizer': keras.regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_regularizer': keras.regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_constraint': keras.constraints.serialize(self.gamma_constraint),\n",
    "            'beta_constraint': keras.constraints.serialize(self.beta_constraint),\n",
    "        }\n",
    "        base_config = super(LayerNormalization2, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def compute_mask(self, inputs, input_mask=None):\n",
    "        return input_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = keras.layers.InputSpec(shape=input_shape)\n",
    "        shape = input_shape[-1:]\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(\n",
    "                shape=shape,\n",
    "                initializer=self.gamma_initializer,\n",
    "                regularizer=self.gamma_regularizer,\n",
    "                constraint=self.gamma_constraint,\n",
    "                name='gamma',\n",
    "            )\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(\n",
    "                shape=shape,\n",
    "                initializer=self.beta_initializer,\n",
    "                regularizer=self.beta_regularizer,\n",
    "                constraint=self.beta_constraint,\n",
    "                name='beta',\n",
    "            )\n",
    "        super(LayerNormalization2, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        mean = K.mean(inputs, axis=-1, keepdims=True)\n",
    "        variance = K.mean(K.square(inputs - mean), axis=-1, keepdims=True)\n",
    "        std = K.sqrt(variance + self.epsilon)\n",
    "        outputs = (inputs - mean) / std\n",
    "        if self.scale:\n",
    "            outputs *= self.gamma\n",
    "        if self.center:\n",
    "            outputs += self.beta\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class FeedForward(keras.layers.Layer):\n",
    "    \"\"\"Position-wise feed-forward layer.\n",
    "    See: https://arxiv.org/pdf/1706.03762.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 units,\n",
    "                 activation='relu',\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"Initialize the layer.\n",
    "        :param units: Dimension of hidden units.\n",
    "        :param activation: Activation for the first linear transformation.\n",
    "        :param use_bias: Whether to use the bias term.\n",
    "        :param kernel_initializer: Initializer for kernels.\n",
    "        :param bias_initializer: Initializer for kernels.\n",
    "        :param kernel_regularizer: Regularizer for kernels.\n",
    "        :param bias_regularizer: Regularizer for kernels.\n",
    "        :param kernel_constraint: Constraint for kernels.\n",
    "        :param bias_constraint: Constraint for kernels.\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.units = int(units)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
    "        self.W1, self.b1 = None, None\n",
    "        self.W2, self.b2 = None, None\n",
    "        super(FeedForward, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'activation': keras.activations.serialize(self.activation),\n",
    "            'use_bias': self.use_bias,\n",
    "            'kernel_initializer': keras.initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': keras.initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': keras.constraints.serialize(self.bias_constraint),\n",
    "        }\n",
    "        base_config = super(FeedForward, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def compute_mask(self, inputs, input_mask=None):\n",
    "        return input_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = int(input_shape[-1])\n",
    "        self.W1 = self.add_weight(\n",
    "            shape=(feature_dim, self.units),\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            name='{}_W1'.format(self.name),\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.b1 = self.add_weight(\n",
    "                shape=(self.units,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                name='{}_b1'.format(self.name),\n",
    "            )\n",
    "        self.W2 = self.add_weight(\n",
    "            shape=(self.units, feature_dim),\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            name='{}_W2'.format(self.name),\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.b2 = self.add_weight(\n",
    "                shape=(feature_dim,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                name='{}_b2'.format(self.name),\n",
    "            )\n",
    "        super(FeedForward, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        h = K.dot(x, self.W1)\n",
    "        if self.use_bias:\n",
    "            h = K.bias_add(h, self.b1)\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        y = K.dot(h, self.W2)\n",
    "        if self.use_bias:\n",
    "            y = K.bias_add(y, self.b2)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(keras.layers.Layer):\n",
    "    r\"\"\"The attention layer that takes three inputs representing queries, keys and values.\n",
    "    \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{Q K^T}{\\sqrt{d_k}}) V\n",
    "    See: https://arxiv.org/pdf/1706.03762.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"Initialize the layer.\n",
    "        :param return_attention: Whether to return attention weights.\n",
    "        :param history_only: Whether to only use history data.\n",
    "        :param kwargs: Arguments for parent class.\n",
    "        \"\"\"\n",
    "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "        }\n",
    "        base_config = super(ScaledDotProductAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            query_shape, key_shape, value_shape = input_shape\n",
    "        else:\n",
    "            query_shape = key_shape = value_shape = input_shape\n",
    "        output_shape = query_shape[:-1] + value_shape[-1:]\n",
    "        if self.return_attention:\n",
    "            attention_shape = query_shape[:2] + (key_shape[1],)\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[0]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            query, key, value = inputs\n",
    "        else:\n",
    "            query = key = value = inputs\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[1]\n",
    "        feature_dim = K.shape(query)[-1]\n",
    "        e = K.batch_dot(query, key, axes=2) / K.sqrt(K.cast(feature_dim, dtype=K.floatx()))\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        if self.history_only:\n",
    "            query_len, key_len = K.shape(query)[1], K.shape(key)[1]\n",
    "            indices = K.expand_dims(K.arange(key_len), axis=0)\n",
    "            upper = K.expand_dims(K.arange(query_len), axis=-1)\n",
    "            e *= K.expand_dims(K.cast(indices <= upper, K.floatx()), axis=0)\n",
    "        if mask is not None:\n",
    "            e *= K.cast(K.expand_dims(mask, axis=-2), K.floatx())\n",
    "        a = e / (K.sum(e, axis=-1, keepdims=True) + K.epsilon())\n",
    "        v = K.batch_dot(a, value)\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v\n",
    "    \n",
    "\n",
    "\n",
    "class MultiHeadAttention3(keras.layers.Layer):\n",
    "    \"\"\"Multi-head attention layer.\n",
    "    See: https://arxiv.org/pdf/1706.03762.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 head_num,\n",
    "                 activation='relu',\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 history_only=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"Initialize the layer.\n",
    "        :param head_num: Number of heads.\n",
    "        :param activation: Activations for linear mappings.\n",
    "        :param use_bias: Whether to use bias term.\n",
    "        :param kernel_initializer: Initializer for linear mappings.\n",
    "        :param bias_initializer: Initializer for linear mappings.\n",
    "        :param kernel_regularizer: Regularizer for linear mappings.\n",
    "        :param bias_regularizer: Regularizer for linear mappings.\n",
    "        :param kernel_constraint: Constraints for linear mappings.\n",
    "        :param bias_constraint: Constraints for linear mappings.\n",
    "        :param history_only: Whether to only use history in attention layer.\n",
    "        \"\"\"\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.head_num = head_num\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = keras.constraints.get(bias_constraint)\n",
    "        self.history_only = history_only\n",
    "        self.Wq, self.Wk, self.Wv, self.Wo = None, None, None, None\n",
    "        self.bq, self.bk, self.bv, self.bo = None, None, None, None\n",
    "        super(MultiHeadAttention3, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'head_num': int(self.head_num),\n",
    "            'activation': keras.activations.serialize(self.activation),\n",
    "            'use_bias': self.use_bias,\n",
    "            'kernel_initializer': keras.initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': keras.initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': keras.constraints.serialize(self.bias_constraint),\n",
    "            'history_only': self.history_only,\n",
    "        }\n",
    "        base_config = super(MultiHeadAttention3, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            q, k, v = input_shape\n",
    "            return q[:-1] + (v[-1],)\n",
    "        return input_shape\n",
    "\n",
    "    def compute_mask(self, inputs, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return input_mask[0]\n",
    "        return input_mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            q, k, v = input_shape\n",
    "        else:\n",
    "            q = k = v = input_shape\n",
    "        feature_dim = int(v[-1])\n",
    "        if feature_dim % self.head_num != 0:\n",
    "            raise IndexError('Invalid head number %d with the given input dim %d' % (self.head_num, feature_dim))\n",
    "        self.Wq = self.add_weight(\n",
    "            shape=(int(q[-1]), feature_dim),\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            name='%s_Wq' % self.name,\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.bq = self.add_weight(\n",
    "                shape=(feature_dim,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                name='%s_bq' % self.name,\n",
    "            )\n",
    "        self.Wk = self.add_weight(\n",
    "            shape=(int(k[-1]), feature_dim),\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            name='%s_Wk' % self.name,\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.bk = self.add_weight(\n",
    "                shape=(feature_dim,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                name='%s_bk' % self.name,\n",
    "            )\n",
    "        self.Wv = self.add_weight(\n",
    "            shape=(int(v[-1]), feature_dim),\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            name='%s_Wv' % self.name,\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.bv = self.add_weight(\n",
    "                shape=(feature_dim,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                name='%s_bv' % self.name,\n",
    "            )\n",
    "        self.Wo = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            name='%s_Wo' % self.name,\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.bo = self.add_weight(\n",
    "                shape=(feature_dim,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                name='%s_bo' % self.name,\n",
    "            )\n",
    "        super(MultiHeadAttention3, self).build(input_shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def _reshape_to_batches(x, head_num):\n",
    "        input_shape = K.shape(x)\n",
    "        batch_size, seq_len, feature_dim = input_shape[0], input_shape[1], input_shape[2]\n",
    "        head_dim = feature_dim // head_num\n",
    "        x = K.reshape(x, (batch_size, seq_len, head_num, head_dim))\n",
    "        x = K.permute_dimensions(x, [0, 2, 1, 3])\n",
    "        return K.reshape(x, (batch_size * head_num, seq_len, head_dim))\n",
    "\n",
    "    @staticmethod\n",
    "    def _reshape_from_batches(x, head_num):\n",
    "        input_shape = K.shape(x)\n",
    "        batch_size, seq_len, feature_dim = input_shape[0], input_shape[1], input_shape[2]\n",
    "        x = K.reshape(x, (batch_size // head_num, head_num, seq_len, feature_dim))\n",
    "        x = K.permute_dimensions(x, [0, 2, 1, 3])\n",
    "        return K.reshape(x, (batch_size // head_num, seq_len, feature_dim * head_num))\n",
    "\n",
    "    @staticmethod\n",
    "    def _reshape_mask(mask, head_num):\n",
    "        if mask is None:\n",
    "            return mask\n",
    "        seq_len = K.shape(mask)[1]\n",
    "        mask = K.expand_dims(mask, axis=1)\n",
    "        mask = K.tile(mask, [1, head_num, 1])\n",
    "        return K.reshape(mask, (-1, seq_len))\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list):\n",
    "            q, k, v = inputs\n",
    "        else:\n",
    "            q = k = v = inputs\n",
    "        if isinstance(mask, list):\n",
    "            q_mask, k_mask, v_mask = mask\n",
    "        else:\n",
    "            q_mask = k_mask = v_mask = mask\n",
    "        q = K.dot(q, self.Wq)\n",
    "        k = K.dot(k, self.Wk)\n",
    "        v = K.dot(v, self.Wv)\n",
    "        if self.use_bias:\n",
    "            q += self.bq\n",
    "            k += self.bk\n",
    "            v += self.bv\n",
    "        if self.activation is not None:\n",
    "            q = self.activation(q)\n",
    "            k = self.activation(k)\n",
    "            v = self.activation(v)\n",
    "        y = ScaledDotProductAttention(\n",
    "            history_only=self.history_only,\n",
    "            name='%s-Attention' % self.name,\n",
    "        )(\n",
    "            inputs=[\n",
    "                self._reshape_to_batches(q, self.head_num),\n",
    "                self._reshape_to_batches(k, self.head_num),\n",
    "                self._reshape_to_batches(v, self.head_num),\n",
    "            ],\n",
    "            mask=[\n",
    "                self._reshape_mask(q_mask, self.head_num),\n",
    "                self._reshape_mask(k_mask, self.head_num),\n",
    "                self._reshape_mask(v_mask, self.head_num),\n",
    "            ],\n",
    "        )\n",
    "        y = self._reshape_from_batches(y, self.head_num)\n",
    "        y = K.dot(y, self.Wo)\n",
    "        if self.use_bias:\n",
    "            y += self.bo\n",
    "        if self.activation is not None:\n",
    "            y = self.activation(y)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef4b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Old best\n",
    "\n",
    "def convnext_mha_v2(input_shape, output_shape=1, dense_units=512, activation='relu', dropout=0.1):\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(input_shape[0], input_shape[1]))\n",
    "\n",
    "    def residual_stage(filters, kernel_size=3, activation='relu', num_layers=5, dropout=0.1):\n",
    "        stage = keras.Sequential()\n",
    "        stage.add(keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                activation=None,\n",
    "                                use_bias=False,\n",
    "                                padding='same',))\n",
    "        stage.add(keras.layers.LayerNormalization())\n",
    "        stage.add(keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=1,\n",
    "                                activation=None,\n",
    "                                use_bias=False,\n",
    "                                padding='same',))\n",
    "\n",
    "        base_rate = 2\n",
    "        for i in range(1, num_layers):\n",
    "            stage.add(keras.layers.Activation('relu'))\n",
    "            stage.add(keras.layers.Dropout(dropout))\n",
    "            stage.add(keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                activation=None,\n",
    "                                use_bias=False,\n",
    "                                padding='same',))\n",
    "            #stage.add(keras.layers.BatchNormalization())\n",
    "            stage.add(keras.layers.Conv1D(filters=filters,\n",
    "                                          kernel_size=1,\n",
    "                                          strides=1,\n",
    "                                          padding='same',))\n",
    "\n",
    "        return stage\n",
    "\n",
    "    def big_stage(nn, depth=192, kernel_size=19, activation='relu', num_layers=5, dropout=0.1, max_pool=True):\n",
    "        inputs = keras.layers.Input(shape=nn.shape[1:])\n",
    "        nn = keras.layers.Conv1D(filters=depth, kernel_size=kernel_size, use_bias=True, padding='same',)(inputs)\n",
    "        #nn = RevCompConv1D(filters=128, kernel_size=19, padding='same', concat=True)(inputs)\n",
    "        nn = keras.layers.LayerNormalization()(nn)\n",
    "        nn = keras.layers.Activation(activation)(nn)\n",
    "        nn_hold = nn\n",
    "        for i in range(3):\n",
    "            nn_hold_2 = nn\n",
    "            stage = residual_stage(depth, kernel_size=3, activation='relu', num_layers=num_layers, dropout=dropout)\n",
    "            nn = stage(nn)\n",
    "            nn = keras.layers.Dropout(dropout)(nn)\n",
    "            nn = tfa.layers.StochasticDepth()([nn_hold_2, nn])\n",
    "            nn = keras.layers.Activation('relu')(nn)\n",
    "        nn = keras.layers.Dropout(dropout)(nn)\n",
    "        nn = keras.layers.Add()([nn, nn_hold])\n",
    "        if max_pool:\n",
    "            outputs = keras.layers.MaxPool1D(pool_size=5, padding='same', strides=1)(nn) #22\n",
    "        else:\n",
    "            outputs = keras.layers.GlobalAveragePooling1D()(nn)\n",
    "        return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "    def dense_stage(depth=256, dropout=0.1):\n",
    "        stage = keras.Sequential()\n",
    "        stage.add(keras.layers.Dense(dense_units))\n",
    "        stage.add(keras.layers.LayerNormalization())\n",
    "        stage.add(keras.layers.Activation('relu'))\n",
    "        stage.add(keras.layers.Dropout(dropout))\n",
    "        return stage\n",
    "\n",
    "    stages = []\n",
    "\n",
    "    # layer 1\n",
    "    depth = 192\n",
    "    nn = big_stage(inputs, depth=depth, kernel_size=19, activation=activation, num_layers=4)(inputs)\n",
    "\n",
    "    # layer 1\n",
    "    depth = 256\n",
    "    nn = big_stage(nn, depth=depth, kernel_size=11, activation=activation, num_layers=4)(nn)\n",
    "\n",
    "    # layer 5\n",
    "    depth = 128\n",
    "    #nn = big_stage(nn, depth=depth, kernel_size=5, activation=activation, num_layers=4, max_pool=False)(nn)\n",
    "    nn = big_stage(nn, depth=depth, kernel_size=5, activation=activation, num_layers=4)(nn)\n",
    "\n",
    "    \n",
    "    n_attention_layers = 2\n",
    "\n",
    "    for i in range(n_attention_layers):\n",
    "        mha_input = nn\n",
    "        #nn, att = MultiHeadAttention2(num_heads=8, d_model=96, kernel_regularizer=keras.regularizers.l1_l2(l1=0,l2=1e-4))(nn, nn, nn)\n",
    "        #nn, att = MultiHeadAttention2(num_heads=8, d_model=96)(nn, nn, nn)\n",
    "        nn = MultiHeadAttention3(head_num=8,name='Multi-Head'+str(i), kernel_regularizer = keras.regularizers.l1_l2(l1=0, l2=1e-4))(nn)\n",
    "        nn = keras.layers.Dropout(0.2)(nn)\n",
    "\n",
    "        nn = keras.layers.Add()([mha_input, nn])\n",
    "        nn = keras.layers.LayerNormalization()(nn)\n",
    "\n",
    "        ff_input = nn\n",
    "        nn = FeedForward(units = 8, kernel_regularizer=keras.regularizers.l1_l2(l1=0,l2=1e-4))(nn)\n",
    "        nn = keras.layers.Dropout(0.2)(nn)\n",
    "\n",
    "        nn = keras.layers.Add()([ff_input, nn])\n",
    "        nn = keras.layers.LayerNormalization()(nn)\n",
    "    \n",
    "\n",
    "    \n",
    "    nn = keras.layers.Bidirectional(keras.layers.LSTM(8, return_sequences=True, kernel_regularizer=keras.regularizers.l1_l2(l1=0,l2=1e-4), kernel_initializer='he_normal', dropout = 0.2))(nn)\n",
    "    nn = keras.layers.Dropout(0.2)(nn)\n",
    "\n",
    "\n",
    "    nn = keras.layers.Flatten()(nn)\n",
    "\n",
    "    # layer 6 - Fully-connected\n",
    "    nn = dense_stage(depth=dense_units, dropout=dropout)(nn)\n",
    "    nn = dense_stage(depth=dense_units, dropout=0.5)(nn)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = keras.layers.Dense(output_shape, activation='linear', use_bias=True)(nn)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d2519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomConcat(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, num_layers, *args, **kwargs):\n",
    "\n",
    "        super(RandomConcat, self).__init__(*args, **kwargs)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.loss_combo = tf.convert_to_tensor([[1, 0], [0, 1]], dtype='float32')\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_layers\": self.num_layers,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        N = tf.shape(inputs)[0]\n",
    "\n",
    "        if training:\n",
    "            active_layers = tf.random.uniform(shape=(N,), minval=0, maxval=self.num_layers, dtype='int32')\n",
    "            ind = tf.transpose(tf.concat([[tf.range(N)], [active_layers]], axis=0))\n",
    "            outputs = tf.expand_dims(tf.gather_nd(inputs, ind), axis=1)\n",
    "            return outputs\n",
    "        else:\n",
    "            return tf.expand_dims(tf.math.reduce_mean(inputs, axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d5cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inputs = keras.Input(shape=(111, 4))\\n\\nmodel1 = MyModel((111, 4), dense_units=256)(inputs)\\nmodel2 = convnext_mha_v2((111, 4), dense_units=256)(inputs)\\n\\nnn = tf.convert_to_tensor([model1, model2])\\noutputs = RandomConcat(2)(nn)\\n\\nmodel = keras.Model(inputs=inputs, outputs=outputs)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MyModel(input_shape, output_shape=1, dense_units=512, activation='relu', dropout=0.1):\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(input_shape[0], input_shape[1]))\n",
    "\n",
    "    def residual_stage(filters, kernel_size=3, activation='relu', num_layers=5, dropout=0.1):\n",
    "        stage = keras.Sequential()\n",
    "        stage.add(keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                activation=None,\n",
    "                                use_bias=False,\n",
    "                                padding='same',))\n",
    "        stage.add(keras.layers.LayerNormalization())\n",
    "        stage.add(keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=1,\n",
    "                                activation=None,\n",
    "                                use_bias=False,\n",
    "                                padding='same',))\n",
    "\n",
    "        base_rate = 2\n",
    "        for i in range(1, num_layers):\n",
    "            stage.add(keras.layers.Activation('relu'))\n",
    "            stage.add(keras.layers.Dropout(dropout))\n",
    "            stage.add(keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                activation=None,\n",
    "                                use_bias=False,\n",
    "                                padding='same',))\n",
    "            #stage.add(keras.layers.BatchNormalization())\n",
    "            stage.add(keras.layers.Conv1D(filters=filters,\n",
    "                                          kernel_size=1,\n",
    "                                          strides=1,\n",
    "                                          padding='same',))\n",
    "\n",
    "        return stage\n",
    "\n",
    "    def big_stage(nn, depth=192, kernel_size=19, activation='relu', num_layers=5, dropout=0.1, max_pool=True):\n",
    "        inputs = keras.layers.Input(shape=nn.shape[1:])\n",
    "        nn = keras.layers.Conv1D(filters=depth, kernel_size=kernel_size, use_bias=True, padding='same',)(inputs)\n",
    "        #nn = RevCompConv1D(filters=128, kernel_size=19, padding='same', concat=True)(inputs)\n",
    "        nn = keras.layers.LayerNormalization()(nn)\n",
    "        nn = keras.layers.Activation(activation)(nn)\n",
    "        nn_hold = nn\n",
    "        for i in range(3):\n",
    "            nn_hold_2 = nn\n",
    "            stage = residual_stage(depth, kernel_size=3, activation='relu', num_layers=num_layers, dropout=dropout)\n",
    "            nn = stage(nn)\n",
    "            nn = keras.layers.Dropout(dropout)(nn)\n",
    "            nn = tfa.layers.StochasticDepth()([nn_hold_2, nn])\n",
    "            nn = keras.layers.Activation('relu')(nn)\n",
    "        nn = keras.layers.Dropout(dropout)(nn)\n",
    "        nn = keras.layers.Add()([nn, nn_hold])\n",
    "        if max_pool:\n",
    "            outputs = keras.layers.MaxPool1D(pool_size=5, padding='same', strides=1)(nn) #22\n",
    "        else:\n",
    "            outputs = keras.layers.GlobalAveragePooling1D()(nn)\n",
    "        return ProfileModel(inputs=inputs, outputs=outputs) ###########################\n",
    "\n",
    "\n",
    "    def dense_stage(depth=256, dropout=0.1):\n",
    "        stage = keras.Sequential()\n",
    "        stage.add(keras.layers.Dense(dense_units))\n",
    "        stage.add(keras.layers.LayerNormalization())\n",
    "        stage.add(keras.layers.Activation('relu'))\n",
    "        stage.add(keras.layers.Dropout(dropout))\n",
    "        return stage\n",
    "\n",
    "    stages = []\n",
    "\n",
    "    # layer 1\n",
    "    depth = 192\n",
    "    nn = big_stage(inputs, depth=depth, kernel_size=19, activation=activation, num_layers=4)(inputs)\n",
    "\n",
    "    # layer 1\n",
    "    depth = 256\n",
    "    nn = big_stage(nn, depth=depth, kernel_size=11, activation=activation, num_layers=4)(nn)\n",
    "\n",
    "    # layer 5\n",
    "    depth = 288\n",
    "    #nn = big_stage(nn, depth=depth, kernel_size=5, activation=activation, num_layers=4, max_pool=False)(nn)\n",
    "    nn = big_stage(nn, depth=depth, kernel_size=5, activation=activation, num_layers=4)(nn)\n",
    "\n",
    "    for i in range(2):\n",
    "        nn1 = keras.layers.LayerNormalization()(nn)\n",
    "        nn1, att = MultiHeadAttention2(num_heads=8, d_model=288)(nn1, nn1, nn1)\n",
    "        nn1 = keras.layers.Dropout(0.2)(nn1)\n",
    "        nn = tf.add(nn, nn1)\n",
    "        nn = keras.layers.LayerNormalization()(nn)\n",
    "        nn1 = keras.layers.Conv1D(288*2, kernel_size=1)(nn)\n",
    "        nn1 = keras.layers.Dropout(0.2)(nn1)\n",
    "        nn1 = keras.layers.Activation('relu')(nn1)\n",
    "        nn1 = keras.layers.Conv1D(288, kernel_size=1)(nn1)\n",
    "        nn1 = keras.layers.Dropout(0.2)(nn1)\n",
    "        nn = tf.add(nn, nn1)\n",
    "\n",
    "    nn = keras.layers.Flatten()(nn)\n",
    "\n",
    "    # layer 6 - Fully-connected\n",
    "    nn = dense_stage(depth=dense_units, dropout=dropout)(nn)\n",
    "    nn = dense_stage(depth=dense_units, dropout=0.5)(nn)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = keras.layers.Dense(output_shape, activation='linear', use_bias=True)(nn)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class RandomConcat(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, num_layers):\n",
    "\n",
    "        super(RandomConcat, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \n",
    "        if training:\n",
    "            active_layer = tf.random.uniform(shape=(1,), minval=0, maxval=self.num_layers, dtype='int64')\n",
    "            return tf.math.reduce_mean(tf.gather(inputs, active_layer, axis=0), axis=0)\n",
    "        else:\n",
    "            return tf.math.reduce_mean(inputs, axis=0)\n",
    "\n",
    "\"\"\"inputs = keras.Input(shape=(111, 4))\n",
    "\n",
    "model1 = MyModel((111, 4), dense_units=256)(inputs)\n",
    "model2 = convnext_mha_v2((111, 4), dense_units=256)(inputs)\n",
    "\n",
    "nn = tf.convert_to_tensor([model1, model2])\n",
    "outputs = RandomConcat(2)(nn)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1792bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, pool_size, *args, **kwargs):\n",
    "        super(AttentionPooling, self).__init__(*args, **kwargs)\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"pool_size\": self.pool_size,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense = keras.layers.Conv1D(filters=input_shape[-1], kernel_size=1, activation=None, use_bias=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        N, L, F = inputs.shape\n",
    "        inputs = tf.keras.layers.Cropping1D((0, L % self.pool_size))(inputs)\n",
    "        inputs = tf.reshape(inputs, (-1, L//self.pool_size, self.pool_size, F))\n",
    "\n",
    "        raw_weights = self.dense(inputs)\n",
    "        att_weights = tf.nn.softmax(raw_weights, axis=-2)\n",
    "        \n",
    "        return tf.math.reduce_sum(inputs * att_weights, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "477d4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'residual_transformer_modified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19de32a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "functional_1\n",
      "functional_9\n",
      "tf_op_layer_packed\n",
      "random_concat\n"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    with open(f'{model_name}/layer{i}.pickle', 'rb') as handle:\n",
    "        print(model.layers[i].name)\n",
    "        model.layers[i].set_weights(pk.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9ef55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f'{model_name}.h5', custom_objects={\n",
    "        'ProfileModel' : ProfileModel,\n",
    "        'MultiHeadAttention2' : MultiHeadAttention2,\n",
    "        'RevCompConv1D' : RevCompConv1D\n",
    "        })\n",
    "\n",
    "\"\"\"model = tf.keras.models.load_model(model_name + '.h5', custom_objects={\n",
    "        'ProfileModel' : ProfileModel,\n",
    "        'MultiHeadAttention2' : MultiHeadAttention2,\n",
    "        'MultiHeadAttention3' : MultiHeadAttention3,\n",
    "        'FeedForward' : FeedForward,\n",
    "        'RandomConcat' : RandomConcat,\n",
    "        'RevCompConv1D' : RevCompConv1D\n",
    "        })\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a16f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/2000 [..............................] - ETA: 8:49 - loss: 2.5788 - pearsons_r: 0.7493WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_test_batch_end` time: 0.4637s). Check your callbacks.\n",
      "  15/2000 [..............................] - ETA: 14:41 - loss: 2.4960 - pearsons_r: 0.7452"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-529b7e8e8712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpearsons_r\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1382\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_test_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \"\"\"\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_test_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_test_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_called_in_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_predict_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def pearsons_r(y_true1, y_pred1):\n",
    "    y_pred = tf.transpose(y_pred1)\n",
    "    y_true = tf.transpose(y_true1)\n",
    "    y_true = tf.cast(y_true, 'float32')\n",
    "    y_pred = tf.cast(y_pred, 'float32')\n",
    "    eps = tf.constant(1e-7, 'float32')\n",
    "    mean_cross = tf.reduce_mean(tf.multiply(y_true, y_pred), axis=1)\n",
    "    mean_true = tf.reduce_mean(y_true, axis=1)\n",
    "    mean_true_sqr = tf.reduce_mean(tf.math.square(y_true), axis=1)\n",
    "    norm_true = tf.math.sqrt(mean_true_sqr - tf.math.square(mean_true) + eps)\n",
    "\n",
    "    mean_pred = tf.reduce_mean(y_pred, axis=1)\n",
    "    mean_pred_sqr = tf.reduce_mean(tf.math.square(y_pred), axis=1)\n",
    "    norm_pred = tf.math.sqrt(mean_pred_sqr - tf.math.square(mean_pred) + eps)\n",
    "\n",
    "    covariance = mean_cross - tf.multiply(mean_true, mean_pred)\n",
    "    correlation = tf.divide(covariance, tf.math.multiply(norm_true, norm_pred) + eps)\n",
    "\n",
    "    return tf.reduce_mean(correlation)\n",
    "\n",
    "with h5py.File('compressed_dataset_111.h5', 'r') as hf:\n",
    "    x_train = hf['x_train'][-1000000:][:,:,:4]\n",
    "    y_train = hf['y_train'][-1000000:]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.MSE, metrics=[pearsons_r])\n",
    "model.evaluate(x_train, y_train, batch_size=500)\n",
    "\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29260f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"with open('test_sequences.txt') as handle:\n",
    "    print(handle)\n",
    "    raw_data = pd.read_csv(handle, sep='\\n', header=None).to_numpy()\n",
    "    print(raw_data);\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc11942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"max_length = 0\n",
    "\n",
    "def split_inputs_outputs(a):\n",
    "    global max_length\n",
    "    element = a.split('\\t')\n",
    "    seq, label = element[0], element[1]\n",
    "    max_length = len(seq) if len(seq) > max_length else max_length\n",
    "    return seq, label\n",
    "\n",
    "func = np.vectorize(split_inputs_outputs)\n",
    "temp = np.squeeze(raw_data)\n",
    "inputs, outputs = func(temp)\n",
    "del outputs\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def one_hot_encode(seq, L):\n",
    "    seq = np.array(list(seq))\n",
    "    encoded = np.zeros((L, 4))\n",
    "    As = np.where(seq == 'A')[0]\n",
    "    Cs = np.where(seq == 'C')[0]\n",
    "    Ts = np.where(seq == 'T')[0]\n",
    "    Gs = np.where(seq == 'G')[0]\n",
    "    encoded[As] = np.array([1, 0, 0, 0])\n",
    "    encoded[Cs] = np.array([0, 1, 0, 0])\n",
    "    encoded[Gs] = np.array([0, 0, 1, 0])\n",
    "    encoded[Ts] = np.array([0, 0, 0, 1])\n",
    "    return encoded\n",
    "\n",
    "one_hot_inputs = np.vectorize(one_hot_encode, otypes=[np.ndarray])(inputs, 111)\n",
    "one_hot_inputs = np.array(one_hot_inputs.tolist(), dtype=np.dtype('f8'))\n",
    "print(one_hot_inputs.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5cfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import os\n",
    "\n",
    "if os.path.exists('test_seqs.h5'):\n",
    "    os.remove('test_seqs.h5')\n",
    "    \n",
    "hf = h5py.File('test_seqs.h5', 'w')\n",
    "print('created file')\n",
    "hf.create_dataset('x_test', data=one_hot_inputs)\n",
    "print('saved seqs')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be74614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('test_seqs.h5', 'r') as hf:\n",
    "    one_hot_inputs = hf['x_test'][:,:111]\n",
    "print(one_hot_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.squeeze(model.predict(one_hot_inputs, batch_size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c99241",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, base, _ = plt.hist(preds, bins=100)\n",
    "plt.close()\n",
    "cumulative = np.cumsum(values)\n",
    "cumulative = cumulative/np.max(cumulative)\n",
    "plt.plot(base[:-1], cumulative)\n",
    "\n",
    "print(stats.pearsonr(base[:-1], cumulative)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import quantile_transform\n",
    "\n",
    "uniform_preds = quantile_transform(np.expand_dims(preds, axis=1))\n",
    "data = uniform_preds\n",
    "\n",
    "values, base, _ = plt.hist(data, bins=100)\n",
    "plt.close()\n",
    "cumulative = np.cumsum(values)\n",
    "cumulative = cumulative/np.max(cumulative)\n",
    "plt.plot(base[:-1], cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48821f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_submission.json', 'r') as f:\n",
    "    ground = json.load(f)\n",
    "    \n",
    "indices = np.array([int(ind) for ind in list(ground.keys())])\n",
    "\n",
    "PRED_DATA = OrderedDict()\n",
    "\n",
    "for i in indices:\n",
    "    PRED_DATA[str(i)] = float(uniform_preds[i])\n",
    "    \n",
    "def dump_predictions(prediction_dict, prediction_file):\n",
    "    with open(prediction_file, 'w') as f:\n",
    "        json.dump(prediction_dict, f)\n",
    "        \n",
    "dump_predictions(PRED_DATA, f'{model_name}-uniform_preds.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa3851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd598d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb7394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2245baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.sort(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fccadded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71103,)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce3bf1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2     3     5 ... 71097 71098 71101]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e885e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062d5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b69b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23fe554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC 0.9908081007227847\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(worst_preds, best_preds, s=25, alpha=0.5)\n",
    "plt.xlabel('worst linear statistic model')\n",
    "plt.ylabel('best linear statistic model')\n",
    "\n",
    "print('PCC', stats.pearsonr(worst_preds.astype('float32'), best_preds.astype('float32'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80b0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0c5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630f85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20557844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec274e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b370af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_json(json_file='pred_convnext_regularizer.json'):\n",
    "\twith open(json_file, 'r') as f:\n",
    "\t\tground = json.load(f)\n",
    "\tindices = np.array([indice for indice in list(ground.values())])\n",
    " \n",
    "\treturn indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9d7d74",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'modified_residual_transformer.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0fb163200c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'modified_residual_transformer.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean_all_good.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e98324504e21>\u001b[0m in \u001b[0;36mfrom_json\u001b[0;34m(json_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfrom_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pred_convnext_regularizer.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                 \u001b[0mground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindice\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'modified_residual_transformer.json'"
     ]
    }
   ],
   "source": [
    "m1 = from_json('residual_transformer_modified.json')\n",
    "m2 = from_json('mean_all_good.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01c3581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC 0.9999999999999962\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(m1, m2, s=25, alpha=0.5)\n",
    "plt.xlabel('worst linear statistic model')\n",
    "plt.ylabel('best linear statistic model')\n",
    "\n",
    "print('PCC', stats.pearsonr(m1.astype('float32'), m2.astype('float32'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32911216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9045,) (71103,)\n"
     ]
    }
   ],
   "source": [
    "print(m1.shape, preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce26a49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd884792fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAApgklEQVR4nO2db4xc53XenzPDS2lWSTVLaOtYY62oGDWJUpS41Tbamghayo7oQqa0kBwzglg4jVsB+ZBAjLou5RAmmarRInRKffCHQEAFORDBrP4wa6pCQBkmEwOqKXvp3RVNmIxRyCI1tKM1yFFR7oicnX37YfYOZ+/c9/6/d+6d+/y+kHtnduaduzPPnHve55wjSikQQgjJHoVeL4AQQkgwKOCEEJJRKOCEEJJRKOCEEJJRKOCEEJJR1iT5ZLfddptav359kk9JCCGZ5/Tp079SSg1Zjycq4OvXr8fMzEyST0kIIZlHRN63O84UCiGEZBQKOCGEZBQKOCGEZBQKOCGEZBQKOCGEZJREXSiEEJJlpmerOHj8PC7V6ri9XMLE9g0YH6kEvl9YGIETQogHpmereOboGVRrdSgA1Vodu6fmsHf6jOv9njl6BtOz1cjXxAicEEJssEbRi9eXUG80V91HAXj51AUAwMlzC7hUq6MggqalTXe90cTB4+cjj8Ip4ISQXOKU5jCjaFOwq7W642OZIg6gS7xNLrk8RhAo4ISQ3GEn0M8cPYOZ9y/j5LkFV8EOggKwdfJEpPlwCjghJHccPH6+Kx1SbzRx+NQFxDmjzPyiABCJiHMTkxCSK6Znq9oIO4kBk2Y+PAoYgRNCcsPe6TM43JGv7hVR5cMZgRNCcsH0bDX2FIlXbi+XInkcCjghJBccPH4+FeJdMoqY2L4hksdiCoUQ0rd0WgXTIN6ViKsyKeCEkL5k7/SZVf7sXrNrbBjPjm+O9DFdUygi8qKIfCgiP7Ec/yMROSciZ0XkLyJdFSGEhGB6tpoq8QaA109XIy+n95IDfwnAFzoPiMg2AI8AuFcptQnANyNdFSGEhCAqm16URGkfNHFNoSilvi8i6y2H/xDApFLq2sp9Pox0VYQQ4oJTKXwcZetREPW6gubAPwPgt0XkvwP4GMB/UUr9yO6OIvIkgCcBYHh4OODTEeKfpFp6kuTRlcIDrQrH28ulWMrhwxKVfdAkqI1wDYB1AMYATAB4RUTE7o5KqReUUqNKqdGhoaGAT0eIP5Js6UmSR1cKf+CNs9g6eSKV4i1AZPZBk6AR+AcAjiqlFIAfisgygNsALES2MkJCoPuAP/3KPIBo+lCkjTxdcehSEVcWG7iy2LC9bcAoYLGxHOeytAiAJ8aGI/97BI3ApwFsAwAR+QyAtQB+FdGaCAmN7gPeVKovI/G8XXH4TUUMDhj480fviWk17hzauSVyCyHgzUZ4BMAPAGwQkQ9E5KsAXgTwmyvWwr8B8JWVaJyQVOD0AY/DDdBrdFcc/fY6TSa2b0DJKHq+/5XFBp5+dT7GFemplEuxXQl5caE8rrlpV8RrISQyJrZvWLXJZSWtLoWg6F6P9bhdmgVA5lIv5vo613312hJqdfv0CQA0l5OPMaMsm7eDlZikLzE/4E+/Mm87ISVqN4BJr/LQOtdF5+u0c25MvDoPCNBoqvaxKPtVJ8XVa0tYvL7U62WsoiiC5x7dHOt5pICTvsX84Fgj8biiIjdrW5zYXXFYX6ddmqVhE5XGNb/RxPySq9bqKK7Mj/TbI8R6rp0i717x+P13xP53ZzdC0teMj1Tw3KObUSmXIGjlI+OKinqZh/byOv2kjeJKMXVutgI35kf63XTdf+ysNj2WFqZ+eDH2TWRG4KTvGR+pBBJsv+kQr3nouHB7nX6KW6JKMVnP4dVr3ZPdTbxG/tOz1VRG3FYaywr7j52NNQpnBE6IDUFseTrRiyvf7hc754ZREBjF1TV4flNM07NVbJ08gbv2vImtkyfa58juHLoJr9uX3fRste3lzwJxf9EwAifEBqd0iC6i8pKH7iV2zg2rC6U8YOBao4mnpubw1NQcyiUD+x/epH3NTnl/u3PoRnnAwNbJE7brq9bqECQztzIrSJL27dHRUTUzM5PY8xESlLv2vGkrFALgvcmHtL+X5WrI6dkqJl6bbztSOimXDHzx3k/i5LmFttArpY8wKwF6kRhFAdTqjVW7Y1licMDA7DceDP04InJaKTVqPc4InBAbvNjyOrEK96GdWzIj3CYHj5+3FW+gJdSd/bV15eomlzocJlYEN85vpwvFzsetW08WMIqCfTs2xfoczIGTXKHL11qxyxfr0iH9UsYe5WbrrSXDVryBVgrk6rUlCIDfuPVm7BprdSnNwsakGwVB2wV08Ev3xv4lzgic5AY/Pm1dvtjuAxkkX55GomzBevX6EsolQyvK5vFqrZ66yTlBKRnF2At3rFDASW7wK7Re7Ye9tg9GxbaNQ5GJaaOpYN9guj9JourSDgo4yQ1xCa3ffHlY4tooPXku2m7QtcWGYxTeL/Qi8jZhDpzkhrh82n7y5WGJM9/u9EVWKZew9dPrYBdU6wLt7G4/+qNX4g1QwEmOiEto+6VcX/dFVimX8PaeB3D4P/8bHNq5ZdXrfH7nFhzauUXb2rXfo+84W8V6gSkUkhv8bEwGeewkPshx5tu9FCI5vU6z2CYvpKFIiwJOckVSQhsXXvPtXvPk1vs9dl+lXaxj93tZLlSKmsfu6/17iQJOSIbwEiV7tUva3W/qRxdxy1p7WbC7/1NTc5h4dQ49GjXZU14/XcXonet6KuIspe9TGCn1L25/W91UdjOX7XY/HWuLgusZroyMA+s5jQuW0ueIXg4WIPHjlgbS5cOrtTq2Tp5oC77fvDnFu5tee/0p4H1Iv1QG5hFddG09vm3jkDZX7VRR2fllHmXlZV7pdatg2gj7kH6pDMwbOo/33ukzXcdfPnVB6wV3m9hufplPbN/Q1Quc+KPXLhQKeB+S9sECxB7dldORdy669tXu9IJ3+tJ1VGt17J6ay3S3v15TLhk9v6KlgPchSVYGEu+4dULUXSHpuvpZ6fz98ZEK3t7zgKOIU7qDUzKK2P9wvK1ivUAB70OSrAwk3vBSAh/2Csnu993SKcQ/afo8cROzT8l6wUq/4WVj2c7j7RW7Kyxz47PeaGqHKxDvGAXBwd+Nv8e3HxiBE5IATtY+Ey+5azsGBwzctKaA3VNz7dRMZ8QPtNIwJaOIwQEj+IvIOY1lFUnPmSihgBOSAE7pkb3TZ9r/95K7tvJxYxm1emNVaubAG2dtI36lQOdJCNLm5KKAExIBbhuUThvIR9652HXMa+5aAFuh1s2srNUbWFOggAclbU4uCjghIfGyQemUN7XLTVs3osslA1bdNQri20nSEvwcNi7xiVGQriuVNDq5KOCkb/E6wDgsXnt0FzUzxnTHx0cqmNi+AbeXS/io3kDJKLaHJxRFsPO37kC55C+nzW1Me25ZW2z/Hcxze/BL96beyUUXCulLouwH49Y8ymvl6+P332E7c/Lx++/w9BquXr/xJdFUClM/uojmMiU5CrrO7Q8vYvTOdYk0qgqDawQuIi+KyIci8hOb254WESUit8WzPEKCEdXkmjD+bevxZ8c3Y9fY8KpIb9fYMJ4d3+z5NXTSaCpQv71jnveS4Z54aCwr7D92Nu4lhcZLBP4SgG8B+OvOgyJyB4AHAUQzxpqQCImqH0xQ/3ZnvtQawf/ll7u9xHZRftocD1mmKNI+717b6GZhHJyrgCulvi8i621uOgTgawC+E/WiCAlLVJPivXwROI1q85LKsbvP7qk5DKwtrrq0J8FpKtU+7/30xRgoBy4ijwCoKqXmRbMB03HfJwE8CQDDw8NBno4Q33iZXOMFr18EuspXLxG83X0UQPGOGPO8e22jm4WiJ98uFBEZAPB1AN/wcn+l1AtKqVGl1OjQ0JDfpyMkEFH1gwnbGMxLBN9PEWHauVSre/LYG0XBvh29b1blRpAI/NMA7gJgRt+fAvBjEfktpdQvo1wcIWHojIrNHPPuqTlfI+bCTrL3EsFzsEJy3F4u2f5NnQZkpBlPMzFXcuD/Syl1t81tPwcwqpT6ldvjcCYm6QXWHDPQiqKT8PXaPbeglSIplwyIQFs1SaIlqb95HOhmYnqxER4B8AMAG0TkAxH5ahwLJCQu3CyFcRb8WBtUmeINtFwOFO/keOy+/uvQ6SrgSqnHlVKfVEoZSqlPKaX+p+X29V6ib0J6hVMe2s7nvXtqblWDqbB0Nqiibbt3nDy30OslRA5L6Unf41Roo3OAHD51IfLSe25W9pZ+PP8UcNL3ODlJdB9qBbhWbepSL7rjaetklzf68fyzFwrpe5ycJAePn9c6QJwiNl2Bzsz7l/H66eqq4xOvzWP/sbOo1RurcuAkOYyipK6TYBR4cqFEBV0oJG1Mz1axe2rOVlQrK0JvJ/y6cuyCgP1JUkZBgP/x5S2Z3sDUuVAYgfcBbt3yiJ7xkQpm3r+Mw6curBLxklHEto1D2ihbF7VTvNNFlq2DXmAOPON46ZaX9HqS6MEdJaN3rkO5o2y6XDLw3KObcfLcgq390K4lLEkfgwNGX4s3wAg883jptZEUUfbgTgq7QptrS62JNf3oWuhniiJYVipXV6EU8Ixipk2CbMAFfS63FE3YLxOn54krTaRb8/5jZ1EQsR13RnqPdTO431MlOijgGcQuarQSlWXKT1Qdpge3k6vjzXd/sapiMcrIXre2LPSCzitW8Rb0Z5WlF5gDzyBuk1qiHL7qZ7KN18k0fp7n5VMXbMvNg0zXCbo2kh7sbJgK/Vll6QUKeAZximijHr7qJ6oO03o1SMonijSRl9aiJB2US4bWQ5/X/QqmUDKIrv1opVyKfAirn8k2bq1XnfLYQVqqukXPbnlz8/Z6o0n/dga4en0JgwOG7RVZXq+kKOAZJKppM3E8l24yjVsufWL7Bjw1Ned5XW6vVzem7KmpOVRW+j93VkxSvNNPo6lwrdFEySgm8t7PAkyhZJCops0k+VxuufTxkQrKJW8jrEyfttMadE2qgJaYHz51wXEfgaSTxcZyYu/9LMAIPKPoIt00Ptf0bNWT3XH/w5sw8eo8GppwuOLRPuj0fCYMuLNLku/9tEMBJ4Hx4s02Uxk6OnOX5u+ajZ9MyiUD+x/e5Em4v370XSw2loO8HJISnBp+CVp/Zwp4Cwo4CYRXf7iT5dEud2n+budj1+oNV9/39GwVE6/No9FkbJ11nP6CCvD0XshLbyDmwEkgvPrDnexdzz26GQC6eqf48Z53rofinQ+c3gtp6w0UNxRwEgiv/nCdvcucEWn3YdPlr6u1urZRVl59wGnnpjWF9t/aDgn4uLq/d5Av/yxDASeB8Fp1uW3jkO39tm0c0n7YimL/sRZAO7vyVg8OFtO5QJLj2tKy44ayQqtroF90778w7RyyCAWcBMKp6rKzpeyRdy7a/v7JcwvaD1VTqa7H1pVQv3zqArYceMu1d4m5trwWfKSVcsnAxz43nZ1832HaOWQRCjgJhM4fDqxOi+i6+ZkbTHaYj9X52E7ZbTfxFgFuNgrYPTWHD/9vf0ZiWUQAXF9q+vLju/m+w7RzyCIcqUYiRTdqzEq5ZEAEXWXRuragXh+X9CdGQXDwd+8N3ZY4q3CkGkkEL7lGoyC4en2pyzUi6K7ONNm2cYiTcPqMokO/dRHAvMmsAwBaX+RuwpynQh8KeA6JM0LRNaWSjtsXry/ZNiTqLHXv9PpOz1Zx5If2uXSSTaz9TKwcsgwhzuK0pyRgDjxnxO2Tndi+AUah2+uxpih4YmwYQHfaxI56o4mnX5nHXXvexJ+8Mocmu031nF1jw5771TjRucdhx+CA0SXKebMHeoUCnjOi+CA4DS4eH6ng127uvrBrNBUOn7rgK4/dVAoK7BSYBkRaw5/NeaFBKBlFPL9zC97e80C7A6XdhuO+HZu6fjdv9kCvMIWSM8J+ELxcytY0ETZ1OLs8cf8wDrxx1rNjxM72ac4a7UzfPXZfpW0pdUrn3VoybN1G/WoP9AoFPGf4GdBgh5fBxUGGM5DeUnHYmwDgawO54vD3r9UbbSGu1up4/XTVtR3s3ukzWquoWZ1r2gT7zX3iBlMoOSOsT1YXqVdrdUzPVjE9W8Xi9aXQ6yTJsWtsGG/veUB75eQHM0XiVD7fiVv6bnq2isMuXx7VWh0Tr85j4rX53PRAMXEVcBF5UUQ+FJGfdBw7KCLnRORdEflbESnHukoSGWEHNDhF6hOvzWPi1XlPm5QkHawtCp4dbxVghU1H7Bobbr+P/MwadUrfHTx+3lPqrbGsumypedjk9BKBvwTgC5Zj3wVwt1LqHgD/COCZiNdFYmR8pIK39zyA9yYfam8oecXpg9loKu0wBpJOOkUv7IBn84sAsA8UdD1PnL44wm5S9vsmp2sOXCn1fRFZbzn2VsePpwB8KeJ1kQQI4gc3b/czv5KkF7uBGuZ7ouBQaGPFLmViLaixboADrc3OzoZn1vekbvPSK/2+yRlFDvwPAPyd7kYReVJEZkRkZmFhIYKnI1EQxg8+PlIJ1EGOpA9rt0jT3nd7uYSmUp66N3rdQxkfqeCx+yqrHlMBeP10tb1/Yn1PXr2+ZFtX4EW4+rkHikkoF4qI/CmAJQCHdfdRSr0A4AWg1QslzPOR8JgRjp1LwOomcSLBFjokRl4/XcXonevaf3NrlKxwwxJoziQFgrs9Tp5bsLUXmrlqq8Op0VQYHDAwsHbNqucz16BzuxRFcjHsOLCAi8jvA/gigM+pJDtikcDYXcJaccoZdl7eOv3BK+USLtXqKA8Y+H8fN8ARlenF+qVtZxM1xfvtPQ+0jwUVxiB1CLXFBma/8WDX8fGRCu7a86bte3FZqb4XbyCggIvIFwB8DcC/VUotRrsk4hevuWyn+ZQmBZGuobHTs9WuQcM6zA/69Gx1ZcK8/9dDkqUzio274tGtDsFvjULYuoas48VGeATADwBsEJEPROSrAL4F4NcBfFdE5kTkr2JeJ9HgJ5ft5UPYVGrV75uP70W8O3OOB4+fpyMlJdy0puCayzZbIxQ005DUyn3C+qqd6hCC1Cjkrf+3FfYDzzi6PtnWS16n+9oxOGBg9hsPev4dszWors836R1GQSL7MtX1a/eD0xVjEGdUP/b/tsJ+4H2Kn0veie0bXHPgJlcWG5ierbqKd0GAm9bcaA0axvJFoqdkFFCPMI/lZ6PbDjexDdLLO0/9v62wlD7j+JkBaGfjcsKL13tZdTsHSDrYNTbse96kF4Lmw+NuZZxHKOAZx28O0M7GRfqT109XUY7Brx90g5A9vaOHAp4xrL24AfjqbdLvpcXkBvVGE0qh6wvevAKrlEvYNTbsq3w+zAYhe3pHD3PgGULXi/u5Rzd3bVjqCFuaTLLFR/UGDu3c4ph3Hr1zHZ5+Zd62bL5cMnDLTWsi2SDMu+UvDijgGUJ3CfrU1BwOHj+v/XB1bhx5ToAHJOpNM3LD+eFUeajj9nLJ0ybfPyut6XIOlYwi9j+8KbINQrtN9DxZ/uKAAp4hnC417SbjTM9WceCNs6s/mDEnwCne0TI4YGDfjhsi6tVFBLTsg27iqKvONSfBR+nusDbL6lfLX5JQwDOE26SbTouXl7J5kn4G1q5pC1ynAHqJxJeUwm6XqzNdde4tN63pur81IAgi8nm2/MUBNzEzhJd+zWaU7qVs3olKuYStn14Xd8aFuGC96jJ7uT+/c4vre0EpONr1nHz+1uN7p8/gqam5VVdztXoDE6/O0wbYQxiBZwgvEZi5IRRkZ18APDE2vKoxf2f3ws5BtYNsVJUINxv2Mdb4SAUz71/G4VMXPGXFrAU45hWaE1sOvIWP6g3Hje/GsgpV2EPCwQg8YzhFYJ0bQl529sslY5X98NDOLavE23y+bRuHuqaMf1SneCdBvbGsjXD9evrNuaWAtyu0Wr0BBffqWtoAewcj8IzitiHkVjbv5jBw6hsOtCowSTLoItwgwmlG3VGKbhgbYB76mMQJBTzDOG0IWQW+PGBAqVbkrPug6NIlpLfoxNZpU1vXwMpMpbhtiHvFi9NFh66uAejuN06ht4cCnlG8vKH97Pjf6N/d+tBTvNODLsKd2L4Bu6fmbP9Wv3Zzt6/b5FKtjkM7t4R2KZWMAp579J7AQupUWu80S9NJ6PMGc+Apwlomr8t9xtEUaP+xs+zfnVIufVTH3unuDcfxkYr2i7a22LAdNAzcKO7pbMFQLhkYHDAgaG1QW+dQGgVp314pl/D8zi346X/7923Lqpf3bdfr8lhazx4qehiBpwS7KGP31Bxm3r/ctbHoNXLxwt7pMzjyzkXP08dJ/KwtCq43b/w9lAJePnUBALreCxWH8nS3ykenKzSvKYsw0bHX0nr2UNHDCDwl6GYRHj51oSuiieoNvXf6DF4+dYHinRIErRawTY2758g7F7uOOXWjtEbZbo3OOjHdTu9NPtTus2MXZYeJjr120vTTMjlvMAJPCTrxVeh2IUTVFMhOEEhyDA4Y+LjRbLcfKA8YGL1zXTvatmL3RevmRoqi8tEpyg4TTHgtrWcPFT0U8JTg5AqwfhiiekP7ibzpSomefTs2rSqmubLYwDNHz2jPdVEzr9JNpMM6OJyi7LDBhJcvGPZQ0UMBTwi3D5GTo8D6YYjqDW3OsfQCxTtaBgcMrTDesraIq9e73SGP33+H7+fRRc8z71/GyXMLnt4/TlG2nZsljuiYPVTsoYAngNcP0Wc/vQ7/+/9cXiWWug+DVcTNnKOfN/nj99+hvVwn0VGQ1YVPRlGwb8cm7NaMrFu83sSuseH25nJRBI/ff0fXBqYXdF8SnSX4bhuPTlE2o+PeQgFPAK8fostXr+OJsWFPkZFTXtJ8zku1Om5dmRJfW9QX8JD4qKycczuB62r1u0J5wMCz45sDCbYVp72VTpxcTGHcLCReKOAJ4OdDdPLcgqfpOrovhQNvnMXHjWXbKfHVWh1PTc3hwBtnsW/HJm5ixkynG8RO4HTZqyhNQX4qLnXvU0bZ6YUCngBRfIi83k9XfWe9jy7fTqKh4kHkPtI0idIdD4Jd9KzbJHXaeGSUnU4o4AkQ1YcIuLEZGlZ8Kd7xUCmXPM8nTWJGpF30vG3jEF4/XaUtrw+ggCdAVB8ityk7glb/aI416x1+RDBuf7PV+XRo55b2e3H0znVMifQBohKswhsdHVUzMzOJPV/a8evP3Tp5wjUVYxQFjSbj617x88mHPN2vs/Ojaec00y5A+Hyz3Ze9ORyZQp09ROS0UmrUepwReA/xm1f0kkdvNBWLbnpEpVzy9KVsFdemUqsi7yg670XZL4ekFwp4hvAqzBTv5BEA2zYOeRJft/4hUQgvG0DlAzazygjTs1UKc0oxZ4mePLfgqbGTk7hGJbxsAJUPKOARELQfsh/Y+ziddM4S9Sq+TuIalfB67fRHso1rCkVEXgTwRQAfKqXuXjm2DsAUgPUAfg7gy0qpK/EtM70kNS2El77pwm5D0Kst0M19EoUzJY3FNxyLFj1ecuAvAfgWgL/uOLYHwPeUUpMismfl5/8a/fLST5ybRRy2kE50RTpebYFexDUKoUtT8Q3HosWDq4Arpb4vIusthx8B8O9W/v9tAH+PnAp4XJtF5rAFJ1qXyIq+7wCYEbRp5fOKk03QT9TrNpC630SNrph4COpC+YRS6hcr//8lgE/o7igiTwJ4EgCGh4cDPl16iauazqlPiaw8/raNQ5j6EfuZ+KVcMrD/4U1t4fA63FfXj7uTfhTfKNAFNNVaHVsnTzCdEpDQm5iqVQmkvcZXSr2glBpVSo0ODQ2FfbrUEddmkVPaxBxzdfLcAot2AnBt6cYVS+fYMTeC9OMmLZwCmiiGcueVoAL+TyLySQBY+ffD6JaULcLMHXTCKdoz3+h+Lv3JDazWPnP+oxO7xoYjae+aV+wCnU44ZT4YQVMoxwB8BcDkyr/fiWxFGSSOy2anYQtPTc3hT16ZY8VlCOwu6XUT3ivlEsU7JJ37A15HBxJ3XCNwETkC4AcANojIByLyVbSE+3dE5GcAPr/yM4mQZ8c3Y9eYfs9gWVG8w3BryVj18/RsFYvXl7ruZxSE3umIMK90dOkqFhn5x4sL5XHNTZ+LeC25xs4j++z45lVTe0h0dGaoHLs8uu9bdkG/szOcMh8d7IXSA+w60XWmQzo9sn6GQRDv1DoGX9hZ3EwaTeXL6ka/sztpLDLKKhTwCPATcdl1ogP0MwrtohXijZJRxM1GwXZKUeflulvu1U9uln5nb9BuGQ3shRISU5CrtToU3C1RTtGelerKtHmn+9+yVr+zn3duWlPAQ/d80tXm6ZZ79ZObZRdAkiQU8JC4tQa14veD7JY+uXqdkbmOWr2B109X8dh9FUebp5PFzW9ull0ASZIwhRISvxEXc9rJUm80cfLcgqPP22pxs07I8XOpzw06kiQU8JD4LaX3ktPW+ZFJC6PQ2vL12gLGy1VPVDlZbtCRJKGAh8RvxGV+kJ9+Zd62XF5WHvOpqbk4lpt5OudGPnP0XU+NvJJOX3CDjiQFc+AhCVJKPz5SwbKm14kCKN4ant+5pZ0KaX1puos30xfxkMQQE+IOI/AI8Btx8c0ejP3HzmJ8pOLZyRMkh03codc9PVDAE8Z887O60j+1egNbJ0+47g8IgEM7t1BMYiKo150VqtFDAU8YPz5w0o0X8X5ibJjCECNOvb3v2vOmrTgzao8H5sATZHq2SndJjAwOGO0BwyQ+nDaFdcVsfusliDcYgceA3aUigHbEQaKhUi7xcrwHeLHCWlMqrFCNBwp4RHQ2qLJrTHWzUWDqJGLchjCQeLB63XX7OZ3iHNfowbzDFEoEdPZDAewbU9k1VCLBGRww3O9EYsPs7f3e5EOe+nvHNXow71DAI4Abk9HiJs5GUbBvx6aEVkPc8CLOcY0ezDtMoUQANyajo2QUsW/HJhx446ztVUtRBAe/dC8/+CnCa/sAVqhGDwU8JF6Kcpz6UpMbDA4Y2LdjU/tDbteigFFbOqE49wYKeEgOvHHW8fZyycD+h1uX+xOvzaPRZAkPAAwYBQzecpM2YmNTKELcoYCHxC2qvroyKHd8pIJnjr5LAV/hJqPo6iJhVEeIMxTwmGk0VTtK99J8KS9cWWyVxW/bOIST5xZiibJZuk36HQp4SMolA7W6cxR+ZbHBDoM2VGt1vHzqwqqfoyqvZuk2yQO0EYZk/8ObeBIjJKryapZukzyQO+2Juo/x+EgFt7KoxBXxcd8oyqtZuk3yQK4E3O8Eea/UaA90pFIu4dDOLdqKPStRlFdzuDDJA7kS8Dguq/dOs7e3E5VyCW/veQDjIxXH6e8mUZVXs3Sb5IFcbWI69THeOnnCs1uhs3EV0WNXTg2s9nbH5UKhj5zkAVGa2YxxMDo6qmZmZhJ7Piu6aS6d3QMB54o/q7uB2GMWMFEwCQmPiJxWSo1aj+cqhWJ3WW0Vb8A5rcLGVS1KRqHdmKhcMjA4YLSbFD2/cwvm9j1I8SYkZnKVQrG7rNalQehicObjxjL7cRPSY0IJuIjsBvCf0ApizwD4j0qpj6NYWFxYy7NH/uwt23J4EdjO93MS/TxBNwchvSewgItIBcAfA/iXSqm6iLwC4PcAvBTR2hJBtwWwvHK8Wqtj4rV5AMDM+5fxi48o3gCwbeNQr5dASO4Jm0JZA6AkIg0AAwAuhV9SdEzPVlf1lbbbWPvIpQweaPUzmXh1DmxlcoOT5xZie2z2MCHEG4EFXClVFZFvArgAoA7gLaXUW5GtLCTTs9Wu9q21egMTr7ai6fGRii8PN8V7NVHvBbjNFAXYw4QQK4FdKCIyCOARAHcBuB3ALSKyy+Z+T4rIjIjMLCzEF7VZOXj8vG3r1saywsHj57F3+syqRkrEH1HmwL3MFGUPE0K6CWMj/DyA95RSC0qpBoCjAD5rvZNS6gWl1KhSanRoKLm8qVOEeKlWx5F3Lia2ln4j6opGL9ZMun8I6SaMgF8AMCYiAyIiAD4H4KfRLCs8ThHi7eUSmgkWMPUTRZHIx5p5EWe6XgjpJrCAK6XeAfAagB+jZSEsAHghonWFxsklsXh9CQU/7fFIm2WlIs9Fu4kze5gQYk+oSkyl1D6l1Eal1N1Kqf+glLoW1cLC4uSSuLLYaNsEiT/iiIR1FbJAq7KTg4wJsaevKjE77WfU5/AUAHSab+KKhNl4ipBg9I2As8lUeCrl0ioBBZITVQ4wJsQ/fSPgbDIVDrNvtxWKKiHppW+6EdJm1k3JKOL5nVvw/M4trvfjJiEh2aNvBJw2s9UI0N78Gx+paMeZxWELJIQkQ98IuJdxXXlCAXhqag7r97yJkT97C9s2DtmOGPvLL99L8SYko/SNgI+PVPDco5t7vYxUcmWxgakfXcRj91XaQxhozyMk+2R2E3N6tor9x86ittJNsCCgt9uBRlPh5LkFDmEgpI/IpIBPz1Yx8eo8Gh2KTfF2hxu9hPQXmUyhHDx+fpV4E29wo5eQ/iKTAs6RZv4xikKrICF9RiYFvCjsROVEuWSgXDLaPw8OGDj4JbpNCOk3MpkDZytYZz6qN/De5EO9XgYhJGZSL+B28xErnAzvCHPdhOSDVKdQOkdtKdyYj7ht4xDylkQxX6+ZPtK9fpbFE5IfUh2B2zWoqjeaOHluAU+MDedmpmXFphNg5xDgogiaStnejxDSv6RawHW+5Uu1Op4db1Vd9ruIO3UJpFATkm9SnULR5XJvLRmYnq3i9dPVhFeULEyHEEKcSLWAT2zfAMNmeOXV60vYf+xsavp/GwXB4IDR7jFitnA1OwBaX4H5c7lkwCiK7W3sVUIIcSPVKZTxkQoOvHEWVxYbq443mqrdA6XXlEsG9j+8yVZozWN2ThovtxFCiBOiEvRUj46OqpmZGV+/c9eeN1M533JwwMC+HfbCTQghUSIip5VSo9bjqY7AgVYe3M7zPThg4OPGcqJpFFlZD6NkQkgaSL2AT2zf0DWsuGQUsW/HJgBoW+nibierc4MQQkivSL2Am5GuLk/cGQlvnTwRSYVmsSBodnwb0A1CCEkjqRdwwLvn2S5a98quseG2t5wbi4SQLJAJAfeKNVovGQXUG8vtTdABo4A/f/QezLx/GUfeuYimUiiK4PH772iLt/k4FGxCSNpJvQuFEELyjs6FkupCHkIIIXoo4IQQklEo4IQQklEo4IQQklEo4IQQklESdaGIyAKA9xN7wuDcBuBXvV5EyuA56YbnxB6el27CnpM7lVJD1oOJCnhWEJEZO8tOnuE56YbnxB6el27iOidMoRBCSEahgBNCSEahgNvzQq8XkEJ4TrrhObGH56WbWM4Jc+CEEJJRGIETQkhGoYATQkhGoYB3ICK7ReSsiPxERI6IyM29XlMvEJEXReRDEflJx7F1IvJdEfnZyr+DvVxj0mjOyUEROSci74rI34pIuYdL7Al256XjtqdFRInIbb1YW6/QnRMR+aOV98tZEfmLKJ6LAr6CiFQA/DGAUaXU3QCKAH6vt6vqGS8B+ILl2B4A31NK/QsA31v5OU+8hO5z8l0Adyul7gHwjwCeSXpRKeAldJ8XiMgdAB4EcCHpBaWAl2A5JyKyDcAjAO5VSm0C8M0onogCvpo1AEoisgbAAIBLPV5PT1BKfR/AZcvhRwB8e+X/3wYwnuSaeo3dOVFKvaWUWlr58RSATyW+sB6jea8AwCEAXwOQO5eE5pz8IYBJpdS1lft8GMVzUcBXUEpV0fpWvADgFwA+Ukq91dtVpYpPKKV+sfL/XwL4RC8Xk0L+AMDf9XoRaUBEHgFQVUrN93otKeIzAH5bRN4RkX8QkX8dxYNSwFdYyek+AuAuALcDuEVEdvV2VelEtbynuYusdIjInwJYAnC412vpNSIyAODrAL7R67WkjDUA1gEYAzAB4BURkbAPSgG/wecBvKeUWlBKNQAcBfDZHq8pTfyTiHwSAFb+jeQSMOuIyO8D+CKAJxSLKgDg02gFQfMi8nO00ko/FpHf6Omqes8HAI6qFj8EsIxWg6tQUMBvcAHAmIgMrHwzfg7AT3u8pjRxDMBXVv7/FQDf6eFaUoGIfAGtPO/DSqnFXq8nDSilziil/rlSar1Saj1awvWvlFK/7PHSes00gG0AICKfAbAWEXRspICvoJR6B8BrAH4M4Axa5yaXJcEicgTADwBsEJEPROSrACYB/I6I/Aytq5XJXq4xaTTn5FsAfh3Ad0VkTkT+qqeL7AGa85JrNOfkRQC/uWIt/BsAX4niio2l9IQQklEYgRNCSEahgBNCSEahgBNCSEahgBNCSEahgBNCSEahgBNCSEahgBNCSEb5/xdwp7drVCidAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(m1, from_json(f'{model_name}.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
